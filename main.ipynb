{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "```\n",
    "python3.6  \n",
    "jupyter == 1.0.0  \n",
    "pytorch == 1.7.0  \n",
    "torchvision  \n",
    "sklearn == 0.23.2  \n",
    "lightgbm == 3.1.0  \n",
    "numpy == 1.19.4  \n",
    "pandas == 1.1.4  \n",
    "fasttext  \n",
    "textdistance[extras]  \n",
    "fuzzywuzzy  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from joblib import dump, load\n",
    "\n",
    "import pandas as pd\n",
    "import fasttext as ft\n",
    "\n",
    "# == Directories ==================================================================================== #\n",
    "# Directories\n",
    "data_path = './data'\n",
    "output_path = './output'\n",
    "model_path = './output/model'\n",
    "\n",
    "# == Script Parameters ============================================================================== #\n",
    "# Images\n",
    "IMG_SIZE = 300\n",
    "IMG_EMB_NAME = 'resnet34'\n",
    "IMG_BATCH = 110\n",
    "\n",
    "# Histograms\n",
    "HIST_BIN_SIZE = 15\n",
    "\n",
    "# Texts\n",
    "TXT_N_FEATURES = 100\n",
    "TXT_N_EPOCH = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Testing Parameters ============================================================================= #\n",
    "# Images\n",
    "LOAD_IMG_FEATURES = False\n",
    "img_features_path = f'{model_path}/test_img_feats_{IMG_SIZE}.joblib'\n",
    "# Histograms\n",
    "LOAD_HIST_FEATURES = False\n",
    "hist_features_path = f'{model_path}/test_hist_feats_{IMG_SIZE}.joblib'\n",
    "# Texts\n",
    "LOAD_TEXT_MODEL = False\n",
    "USE_CLEAN_TEXT = False\n",
    "txt_emb_model_path = f'{model_path}/txt_emb.bin'\n",
    "# Model\n",
    "lgbm_model_path = f'{model_path}/lgbm_hyped.joblib'\n",
    "lgbm_final_features = f'{model_path}/lgbm_final_features.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Loading DataFrames ============================================================================= #\n",
    "train_df = pd.read_csv(f'{data_path}/new_training_set.csv', index_col=0)\n",
    "sample_df = pd.read_csv(f'{data_path}/new_test_sample.csv', index_col=0)\n",
    "test_df = pd.read_csv(f'{data_path}/new_test_set.csv', index_col=0)\n",
    "extra_df = pd.read_csv('preprocessed_extra_titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recalculating test image features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/budiryan/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test image features to ./output/model/test_img_feats_300.joblib\n"
     ]
    }
   ],
   "source": [
    "# == Getting Image Features ========================================================================= #\n",
    "img_subdir = f'{data_path}/img'\n",
    "img_dir = f'{img_subdir}/img'\n",
    "\n",
    "if LOAD_IMG_FEATURES:\n",
    "    print(\"Loading image features from %s\" % img_features_path)\n",
    "    test_img_feats = load(img_features_path)\n",
    "else:\n",
    "    print(\"Recalculating test image features\")\n",
    "    img_model = torch_load_hub_model(IMG_EMB_NAME, cut=-1)\n",
    "    test_img_feats = get_batch_image_feature_vectors(img_model, img_subdir,\n",
    "                                                     img_size=IMG_SIZE, batch_size=IMG_BATCH)\n",
    "    print(\"Saving test image features to %s\" % img_features_path)\n",
    "    dump(test_img_feats, img_features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text model from ./output/model/txt_emb.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# == Getting FT Embedding Model ===================================================================== #\n",
    "if LOAD_TEXT_MODEL:\n",
    "    print(\"Loading text model from %s\" % txt_emb_model_path)\n",
    "    text_model = ft.load_model(txt_emb_model_path)\n",
    "else:\n",
    "    print(\"Preprocessing titles\")\n",
    "    texts = pd.concat([train_df['title_1'], train_df['title_2'], sample_df['title_1'],\n",
    "                       sample_df['title_2'], extra_df['Title'], test_df['title_1'], test_df['title_2']], axis=0)\n",
    "    texts = texts.reset_index().drop('index', axis=1)\n",
    "    texts = texts.rename(columns={0: 'Title'})\n",
    "    texts.index.name = 'pair_index'\n",
    "    texts = preprocess_text_df(texts, txt_cols=['Title'])\n",
    "    if USE_CLEAN_TEXT:\n",
    "        texts = preprocess_text_df(texts, txt_cols['Title'], func=remove_stopwords)\n",
    "    texts.to_csv(f'{output_path}/titles.txt', header=False, index=False)\n",
    "    print(\"Unsupervised training for text model for test data\")\n",
    "    text_model = ft.train_unsupervised(f'{output_path}/titles.txt', minn=3, maxn=6, dim=TXT_N_FEATURES,\n",
    "                                       epoch=TXT_N_EPOCH)\n",
    "    print(\"Saving text model to %s\" % txt_emb_model_path)\n",
    "    text_model.save_model(txt_emb_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Building Features DataFrame ==================================================================== #\n",
    "# preprocess train and test text features\n",
    "train_text_df = train_df.copy()\n",
    "train_text_df = preprocess_text_df(train_text_df)\n",
    "if USE_CLEAN_TEXT:\n",
    "    train_text_df = preprocess_text_df(train_text_df, func=remove_stopwords)\n",
    "test_text_df = test_df.copy()\n",
    "test_text_df = preprocess_text_df(test_text_df)\n",
    "if USE_CLEAN_TEXT:\n",
    "    test_text_df = preprocess_text_df(test_text_df, func=remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build handcraft text feats..\n"
     ]
    }
   ],
   "source": [
    "# build text, images, and histogram sample features\n",
    "img_train_df = build_img_feats(train_df, test_img_feats)\n",
    "text_train_df = build_text_feats(train_text_df, text_model)\n",
    "X_train = pd.concat([text_train_df, img_train_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build handcraft text feats..\n"
     ]
    }
   ],
   "source": [
    "# build text, images, and histogram sample features\n",
    "img_test_df = build_img_feats(test_df, test_img_feats)\n",
    "text_test_df = build_text_feats(test_text_df, text_model)\n",
    "X_test = pd.concat([text_test_df, img_test_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = load(f'train_val_index/train_idx.joblib')\n",
    "val_idx = load(f'train_val_index/val_idx.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_train = X_train.loc[train_idx]\n",
    "y_train_train = y_train.loc[train_idx]\n",
    "\n",
    "X_train_val = X_train.loc[val_idx]\n",
    "y_train_val = y_train.loc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "v7_model = load(f'{model_path}/lgbm_hyped_v7.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "v7_final_feats = load(f'{model_path}/final_features_v7.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = v7_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': 'balanced',\n",
       " 'colsample_bytree': 1.0,\n",
       " 'importance_type': 'split',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 14,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 1,\n",
       " 'min_split_gain': 0.0,\n",
       " 'n_estimators': 450,\n",
       " 'n_jobs': -1,\n",
       " 'num_leaves': 64,\n",
       " 'objective': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'silent': True,\n",
       " 'subsample': 0.8,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 0,\n",
       " 'boosting': 'gbdt',\n",
       " 'min_sum_hessian_in_leaf': 0.01,\n",
       " 'min_data_in_leaf': 80,\n",
       " 'lambda_l2': 0,\n",
       " 'lambda_l1': 0.01,\n",
       " 'feature_fraction': 0.3,\n",
       " 'bagging_freq': 5,\n",
       " 'bagging_fraction': 0.9}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 10\n",
    "params['extra_trees'] = True\n",
    "params['path_smooth'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_hyped = LGBMClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.9, bagging_freq=5, boosting='gbdt',\n",
       "               boosting_type='gbdt', class_weight='balanced',\n",
       "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.3,\n",
       "               importance_type='split', lambda_l1=0.01, lambda_l2=0,\n",
       "               learning_rate=0.1, max_depth=10, min_child_samples=20,\n",
       "               min_child_weight=1, min_data_in_leaf=80, min_split_gain=0.0,\n",
       "               min_sum_hessian_in_leaf=0.01, n_estimators=450, n_jobs=-1,\n",
       "               num_leaves=64, objective=None, path_smooth=0.5,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=0.8, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_hyped.fit(X_train_train[v7_final_feats], y_train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8722815130781754"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "val_preds = lgbm_hyped.predict(X_train_val[v7_final_feats])\n",
    "f1_score(y_train_val, val_preds, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': 'balanced',\n",
       " 'colsample_bytree': 1.0,\n",
       " 'importance_type': 'split',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 10,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 1,\n",
       " 'min_split_gain': 0.0,\n",
       " 'n_estimators': 450,\n",
       " 'n_jobs': -1,\n",
       " 'num_leaves': 64,\n",
       " 'objective': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'silent': True,\n",
       " 'subsample': 0.8,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 0,\n",
       " 'boosting': 'gbdt',\n",
       " 'min_sum_hessian_in_leaf': 0.01,\n",
       " 'min_data_in_leaf': 80,\n",
       " 'lambda_l2': 0,\n",
       " 'lambda_l1': 0.01,\n",
       " 'feature_fraction': 0.3,\n",
       " 'bagging_freq': 5,\n",
       " 'bagging_fraction': 0.9,\n",
       " 'extra_trees': True,\n",
       " 'path_smooth': 0.5}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./output/model/final_params.joblib']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(params, f'{model_path}/final_params.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_hyped_submission = LGBMClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.9, bagging_freq=5, boosting='gbdt',\n",
       "               boosting_type='gbdt', class_weight='balanced',\n",
       "               colsample_bytree=1.0, extra_trees=True, feature_fraction=0.3,\n",
       "               importance_type='split', lambda_l1=0.01, lambda_l2=0,\n",
       "               learning_rate=0.1, max_depth=10, min_child_samples=20,\n",
       "               min_child_weight=1, min_data_in_leaf=80, min_split_gain=0.0,\n",
       "               min_sum_hessian_in_leaf=0.01, n_estimators=450, n_jobs=-1,\n",
       "               num_leaves=64, objective=None, path_smooth=0.5,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=0.8, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_hyped_submission.fit(X_train[v7_final_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Generate Submission File ======================================================================= #\n",
    "# load LGBM model\n",
    "# lgbm_model = load(lgbm_model_path)\n",
    "# final_features = load(lgbm_final_features)\n",
    "\n",
    "predictions = lgbm_hyped_submission.predict(X_test[v7_final_feats])\n",
    "result = pd.DataFrame(predictions, columns=['Label'])\n",
    "result.index.name = 'pair_index'\n",
    "result.to_csv(f'{output_path}/submission_v5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
